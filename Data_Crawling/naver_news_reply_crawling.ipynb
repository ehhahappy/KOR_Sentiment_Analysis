{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **네이버 스포츠 뉴스 크롤링**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **datetime test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20160101',\n",
       " '20160102',\n",
       " '20160103',\n",
       " '20160104',\n",
       " '20160105',\n",
       " '20160106',\n",
       " '20160107',\n",
       " '20160108',\n",
       " '20160109',\n",
       " '20160110',\n",
       " '20160111',\n",
       " '20160112',\n",
       " '20160113',\n",
       " '20160114',\n",
       " '20160115',\n",
       " '20160116',\n",
       " '20160117',\n",
       " '20160118',\n",
       " '20160119',\n",
       " '20160120',\n",
       " '20160121',\n",
       " '20160122',\n",
       " '20160123',\n",
       " '20160124',\n",
       " '20160125',\n",
       " '20160126',\n",
       " '20160127',\n",
       " '20160128',\n",
       " '20160129',\n",
       " '20160130',\n",
       " '20160131']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "startdate=\"20160101\"\n",
    "enddate=\"20160131\"\n",
    "\n",
    "dt_index = pd.date_range(start=startdate, end=enddate)\n",
    "date_list = dt_index.strftime(\"%Y%m%d\").tolist()\n",
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **id,catefory test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 20200829\n",
      " 20200829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['705824', '705962', '706015', '705917', '705996', '706258', '706215', '705997', '706112', '705983', '706217', '706276', '706206', '705967', '706043', '706125', '706018', '706029', '705951', '705825', '706238', '705972', '706012', '705908', '706087', '706175', '705992', '705618', '706225', '705975']\n",
      "['wfootball', 'mlb', 'mlb', 'mlb', 'mlb', 'kbo', 'kbo', 'mlb', 'wbaseballlesson', 'mlb', 'kbo', 'kbo', 'kbo', 'mlb', 'mlb', 'kbo', 'wbaseballlesson', 'hbaseball', 'mlb', 'wfootball', 'kbo', 'wbaseballlesson', 'mlb', 'mlb', 'kovo', 'kbo', 'mlb', 'kbo', 'kbo', 'wbaseballlesson']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "startdate = input()\n",
    "enddate = input()\n",
    "\n",
    "dt_index = pd.date_range(start=startdate, end=enddate)\n",
    "date_list = dt_index.strftime(\"%Y%m%d\").tolist()\n",
    "\n",
    "for date in date_list:\n",
    "    url = \"https://sports.news.naver.com/ranking/index.nhn?type=vod&date=\"+date\n",
    "    res = requests.get(url)\n",
    "    bs = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "    for i in  bs.select(\"script[type]\"):\n",
    "        if 'rankingListModel' in str(i):\n",
    "            id_list = re.findall('(?<=\\\"id\":\")[0-9]\\w+', str(i))\n",
    "            category_list = re.findall('(?<=\\\"categoryId\":\")[a-z]\\w+', str(i))\n",
    "            print(id_list)\n",
    "            print(category_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **url list test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 20200829\n",
      " 20200829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://sports.news.naver.com/wfootball/vod/index.nhn?id=705824',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705962',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=706015',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705917',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705996',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706258',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706215',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705997',\n",
       " 'https://sports.news.naver.com/wbaseballlesson/vod/index.nhn?id=706112',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705983',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706217',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706276',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706206',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705967',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=706043',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706125',\n",
       " 'https://sports.news.naver.com/wbaseballlesson/vod/index.nhn?id=706018',\n",
       " 'https://sports.news.naver.com/hbaseball/vod/index.nhn?id=706029',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705951',\n",
       " 'https://sports.news.naver.com/wfootball/vod/index.nhn?id=705825',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706238',\n",
       " 'https://sports.news.naver.com/wbaseballlesson/vod/index.nhn?id=705972',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=706012',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705908',\n",
       " 'https://sports.news.naver.com/kovo/vod/index.nhn?id=706087',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706175',\n",
       " 'https://sports.news.naver.com/mlb/vod/index.nhn?id=705992',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=705618',\n",
       " 'https://sports.news.naver.com/kbo/vod/index.nhn?id=706225',\n",
       " 'https://sports.news.naver.com/wbaseballlesson/vod/index.nhn?id=705975']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "startdate = input()\n",
    "enddate = input()\n",
    "\n",
    "dt_index = pd.date_range(start=startdate, end=enddate)\n",
    "date_list = dt_index.strftime(\"%Y%m%d\").tolist()\n",
    "\n",
    "for date in date_list:\n",
    "    news_list_url = \"https://sports.news.naver.com/ranking/index.nhn?type=vod&date=\"+date\n",
    "    news_list_res = requests.get(news_list_url)\n",
    "    news_list_bs = BeautifulSoup(news_list_res.content, 'html.parser')\n",
    "\n",
    "    for i in news_list_bs.select(\"script[type]\"):\n",
    "        if 'rankingListModel' in str(i):\n",
    "            id_list = re.findall('(?<=\\\"id\":\")[0-9]\\w+', str(i))\n",
    "            category_list = re.findall('(?<=\\\"categoryId\":\")[a-z]\\w+', str(i))\n",
    "    \n",
    "    news_url_list = []\n",
    "    for i in range(len(id_list)):\n",
    "        news_url_list.append(\"https://sports.news.naver.com/\"+category_list[i]+\"/vod/index.nhn?id=\"+id_list[i])\n",
    "        \n",
    "news_url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 20200829\n",
      " 20200829\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "startdate = input()\n",
    "enddate = input()\n",
    "\n",
    "dt_index = pd.date_range(start=startdate, end=enddate)\n",
    "date_list = dt_index.strftime(\"%Y%m%d\").tolist()\n",
    "news_result_list = []\n",
    "\n",
    "def flatten(I):\n",
    "    flatList = []\n",
    "    for elem in I:\n",
    "        if type(elem) == list: #타입이 list이면 그 안의 원소를 추가\n",
    "            for e in elem:\n",
    "                flatList.append(e)\n",
    "        else: #타입이 list가 아닌 원소라면 바로 추가\n",
    "            flatList.append(elem)\n",
    "    return flatList\n",
    "\n",
    "for date in date_list:\n",
    "    news_list_url = \"https://sports.news.naver.com/ranking/index.nhn?type=vod&date=\"+date\n",
    "    news_list_res = requests.get(news_list_url)\n",
    "    news_list_bs = BeautifulSoup(news_list_res.content, 'html.parser')\n",
    "\n",
    "    for i in news_list_bs.select(\"script[type]\"):\n",
    "        if 'rankingListModel' in str(i):\n",
    "            id_list = re.findall('(?<=\\\"id\":\")[0-9]\\w+', str(i))\n",
    "            category_list = re.findall('(?<=\\\"categoryId\":\")[a-z]\\w+', str(i))\n",
    "    \n",
    "    news_url_list = []\n",
    "    for i in range(len(id_list)):\n",
    "        news_url_list.append(\"https://sports.news.naver.com/\"+category_list[i]+\"/vod/index.nhn?id=\"+id_list[i])\n",
    "        \n",
    "for news in news_url_list:\n",
    "    List = []\n",
    "    news_url = news\n",
    "    n_id = news_url.split(\"id=\")[1]\n",
    "    page = 1\n",
    "    headers = { \"referer\": news_url, \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\" } \n",
    "\n",
    "    while True:\n",
    "        c_url = \"https://apis.naver.com/commentBox/cbox/web_naver_list_jsonp.json?ticket=sports&templateId=view&pool=cbox2&_callback=jQuery1113037310189436772734_1598777228197&lang=ko&country=KR&objectId=vod_\"+n_id+\"&categoryId=&pageSize=20&indexSize=10&groupId=&listType=OBJECT&pageType=more&page=\"+str(page)+\"&initialize=true&userType=&useAltSort=true&replyPageSize=20&sort=NEW\"\n",
    "        res = requests.get(c_url,headers=headers)\n",
    "        cont = BeautifulSoup(res.content, 'html.parser')\n",
    "        total_comm = str(cont).split('comment\":')[1].split(\",\")[0] # 실제 댓글 split\n",
    "\n",
    "        match = re.findall('\"contents\":(.*?),\"userIdNo\"', str(cont)) # \"content\": 뒤에 나오는 전체 문장 끝은 ,\"userIdNo\"로 끝나는...\n",
    "        sympathyCount = re.findall('\"sympathyCount\":([^\\*]*),\"antipathyCount\"', str(cont))\n",
    "        antipathyCount = re.findall('\"antipathyCount\":([^\\*]*),\"userBlind\"', str(cont))\n",
    "        \n",
    "        result = [] \n",
    "        for i in range(str(cont).count(\"\\\"sympathyCount\\\"\")):\n",
    "            result.append({\"contents\":match[i], \"like\":sympathyCount[i], \"dislike\":antipathyCount[i]})\n",
    "        List.append(result)\n",
    "\n",
    "        # 한 번에 댓글이 20개씩 보이기 때문에 한 페이지씩 몽땅 댓글을 긁어오기\n",
    "        if int(total_comm) <= ((page*20)):\n",
    "            break\n",
    "        else: page += 1\n",
    "\n",
    "    news_result_list.append(flatten(List))\n",
    "\n",
    "flatten_news_list = flatten(news_result_list)\n",
    "df_naver_news_reply = pd.DataFrame(flatten_news_list)\n",
    "df_naver_news_reply.to_csv('naver_sportnews_reply_{}_{}.csv'.format(startdate, enddate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>like</th>\n",
       "      <th>dislike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"댓글 없애는거 동의한다. 쓰레기들 아닥할 시간이네ㅋㅋ\"</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"진짜 겁나 간결하네 더 업글된듯\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"내영국친구 ROSE가 말해줬는데 해외에서의 이강인과 쿠보 비교하면 1ㄷ9로 쿠보가...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"동영상 대글은 놔두고 기사대글은 차단하고\\n네이년!!!\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"근데이정도면포텐완전히터진거같다 진짜레알바르샤에서도뛸수준\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>\"이의신청해야지.. 평균자책점 아까워라\"</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>\"1루 송구 실책이 아니었으면 이닝 종료 되니깐 실책으로 투수 비자책이 되는건가요?\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>\"류뚱 실점이 아닌걸로 정정될꺼라 믿는다.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>\"8피안타에 2실점이면 뽀록터졌네\"</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>\"왜 그게 내야안타고 내야야타 하나로 2득점(2자책)이 인정되는게 맞는지 전문가 본...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2928 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               contents  like  dislike\n",
       "0                       \"댓글 없애는거 동의한다. 쓰레기들 아닥할 시간이네ㅋㅋ\"     2        1\n",
       "1                                   \"진짜 겁나 간결하네 더 업글된듯\"     1        0\n",
       "2     \"내영국친구 ROSE가 말해줬는데 해외에서의 이강인과 쿠보 비교하면 1ㄷ9로 쿠보가...     0        4\n",
       "3                      \"동영상 대글은 놔두고 기사대글은 차단하고\\n네이년!!!\"     1        0\n",
       "4                      \"근데이정도면포텐완전히터진거같다 진짜레알바르샤에서도뛸수준\"     3        1\n",
       "...                                                 ...   ...      ...\n",
       "2923                             \"이의신청해야지.. 평균자책점 아까워라\"     5        0\n",
       "2924    \"1루 송구 실책이 아니었으면 이닝 종료 되니깐 실책으로 투수 비자책이 되는건가요?\"     1        0\n",
       "2925                           \"류뚱 실점이 아닌걸로 정정될꺼라 믿는다.\"     0        0\n",
       "2926                                \"8피안타에 2실점이면 뽀록터졌네\"     1       16\n",
       "2927  \"왜 그게 내야안타고 내야야타 하나로 2득점(2자책)이 인정되는게 맞는지 전문가 본...    15        0\n",
       "\n",
       "[2928 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"naver_sportnews_reply_20200829_20200829.csv\", index_col=0)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
